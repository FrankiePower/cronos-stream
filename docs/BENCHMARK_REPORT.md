# âš¡ CronosStream Benchmark Report

## Why We Benchmarked This Way
To prove the speed of the **CronosStream Sequencer**, we needed to isolate the **payment settlement time** from other factors.

### The Challenge: "AI Noise"
A full Agent interaction involves:
1.  **LLM "Thinking"** (1-5 seconds): High variance, depends on OpenAI load.
2.  **Payment Processing** (The generic variable we want to measure).
3.  **Network Request** (Standard latency).

If we benchmarked the full agent, a 3-second delay from OpenAI would hide the difference between a 300ms payment and a 3000ms payment. The "Signal" (Payment Speed) would be lost in the "Noise" (AI Latency).

### The Solution: "Engine Testing"
Our benchmark bypasses the "Brain" (LLM) to test the "Wallet" (Sequencer) directly. It invokes the exact same **PaywallService** code used by the Agent, but in a tight loop.

```mermaid
flowchart TB
    subgraph Full_Agent ["ðŸ¤– Full Agent Flow (User Experience)"]
        direction TB
        U[User Query] --> LLM[ðŸ§  LLM Planner (1-5s)]
        LLM --> DECIDE{Decide to Pay}
        DECIDE --> PAY_SVC[ðŸ’³ Paywall Service]
        PAY_SVC --> ACCESS[Resource Access]
    end

    subgraph Benchmark ["âš¡ Benchmark Flow (Engine Test)"]
        direction TB
        LOOP[Loop 20x] --> PAY_SVC_B[ðŸ’³ Paywall Service]
        PAY_SVC_B --> ACCESS_B[Resource Access]
    end

    style Benchmark fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    style PAY_SVC fill:#66bb6a,stroke:#333,stroke-width:2px
    style PAY_SVC_B fill:#66bb6a,stroke:#333,stroke-width:2px
```

## Results: High-Performance Sequencing ðŸš€

| Metric | Off-Chain Demo | CronosStream (Verified) |
| :--- | :--- | :--- |
| **Throughput** | 100+ TPS (Theoretical) | **27.81 TPS** (Python Client Limit) |
| **Signing Mode** | Pre-Signed | **14.00 TPS** (End-to-End Live) |
| **Reliability** | Poor (timeouts) | **100% Success** (0 failures in 1000 requests) |

### Methodology (Replicating Reference)
We replicated the `reference-1` benchmark methodology (`benchmark.ts`) via `scripts/benchmark_suite.py`:
1.  **Live Signing (14.00 TPS)**: Simulates a real Agent signing and paying sequentially in a tight loop. This measures the full "application latency" (Sign -> Network -> Verify -> DB).
2.  **Pre-Signed Burst (27.81 TPS)**: Pre-generates 1000 signatures and floods the Sequencer. This measures the raw capacity of the validation engine.
    *   *Bottleneck*: The 27.8 TPS is mostly likely capped by the Python `httpx` client's sequential overhead. The Sequencer CPU usage remained minimal.

### What This Means
We have transformed "Agent-to-Agent Payments" from a **slow, fragile process** into a **real-time stream**.
*   **Token Streaming**: At 14 TPS, an Agent can pay for **every single token** generated by an LLM in real-time (usually 10-20 tokens/sec).
*   **Micropayments**: Suitable for high-frequency sensor data, video streaming, or API metering.
